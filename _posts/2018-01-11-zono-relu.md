---
layout: post-right-sidebar
title:  Certifying Robustness of Neural Networks
author: imrahulr
categories: [ Neural Networks, Provable Robustness, Zonotope, Abstract Interpretation ]
image: assets/images/13.jpg
description: A sound and precise automated verifier for certifying robustness of neural networks based on Zonotope abstraction.  
report: https://drive.google.com/file/d/1OD2-nPQSWPRiiz9PI9nS0N2Vljy_VriI/view?usp=sharing
---

> Project for the course "Reliable and Interpretable Artificial Intelligence (263-2400-00L)" with Noman Ahmed Sheikh under Prof. Dr. Martin Vechev.

## Introduction

We implement a precise, sound and scalable automated verifier for proving robustness of neural networks with rectified linear activations (ReLU) against adversarial attacks based on L<sub>&infin;</sub> ball perturbations. The verifier uses <a href="https://files.sri.inf.ethz.ch/website/papers/DeepZ.pdf">Zonotope abstraction</a> to soundly approximate the behavior of the network as precisely as possible.


## Overview

The zonotope domain is exact for affine transformations but loses precision while approximating ReLU functions. The ReLU transformer is parameterized by the slope &lambda; and is sound for any value &lambda; &isin; [0, 1]. <a href="https://files.sri.inf.ethz.ch/website/papers/DeepZ.pdf">Heuristically</a>, the value of &lambda; is chosen as &lambda;&nbsp;=&nbsp;u<sub>i</sub>/(u<sub>i</sub>-l<sub>i</sub>) as it minimizes the area of output zonotope (l<sub>i</sub> and u<sub>i</sub> are lower and upper bounds of i<sup>th</sup> neuron). However, there may exist transformers with different &lambda;, which can verify more precisely. The choice of optimal lambda should be a function of input image and L<sub>&infin;</sub> ball radius rather than minimizing area. 

We propose gradient learning based approach to find optimal &lambda; for each neuron in the network. The objective is to make the existing implementation more precise. We create a network with custom layers that propagates the abstract Zonotope of the input image through a given network. The input zonotope to the network is an L<sub>&infin;</sub> ball of radius &epsilon; around the input x. The network has &lambda; as the parameters learnt using gradient descent. The weights of the original network are freezed. An example network is shown in the figure at the top. Here, the input zonotope has 784 error terms.

Below is a list of propositions and improvements that were implemented in the course of developing our verifier.

- A custom loss function which helps to learn &lambda;'s aiming to certify robustness to the extent possible while being sound.
- Projecting slopes to lie between 0 and 1 during training.
- Computing the loss exactly using simple subtraction (which is affine and exact for zonotope domain) rather than directly using interval domain.
- Adaptive learning rate.

---

## Important Links

<a href="https://files.sri.inf.ethz.ch/website/papers/sp2018.pdf">AI<sup>2</sup>: Safety and Robustness, Certification of Neural Networks with Abstract Interpretation</a><br>
<a href="https://files.sri.inf.ethz.ch/website/papers/DeepZ.pdf">Fast and Effective Robustness Certification</a><br>
<a href="https://drive.google.com/file/d/1OD2-nPQSWPRiiz9PI9nS0N2Vljy_VriI/view?usp=sharing">Report</a>

